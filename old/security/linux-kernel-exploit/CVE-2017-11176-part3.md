# CVE-2017-11176 part3
[LEXFO](https://blog.lexfo.fr/) 홈페이지에 게시되어있는 CVE-2017-11176 관련 문서를 번역하며 공부했습니다.

<br>
part1에서는 CVE 취약점을 분석하기 위한 핵심 개념들을 소개했다. 

우리는 버그가 유효하도록 SystemTap의 도움을 받아 커널영역으로의 트리거를 강제했다. 그리고 권한상승은 아니지만 exploit 코드를 실행해서 취약성을 증명해 보였다.

이번 part에서는 SystemTap 스크립트를 없애고 오직 유저영역 코드만을 이용해서 위 트리거 조건을 만족시키도록 완전한 POC 코드를 컴파일해볼 것이다.

# 핵심개념 #2
두 번째 "핵심개념"에서는 scheduler sybsystem이 소개된다. 여기서 초점을 두어야 하는 부분은 `task 상태`에 대한 부분과 `task의 상태가 어떻게 전환되는지`에 대한 부분이다.

스레드 unblock에 사용될 대기 큐(wait queue)를 강조하며, exploit중에 arbitrary call primitive를 획득할 수 있다.

## Task State
task의 상태는 `task_struct` 구조체의 `state` 필드에 저장된다. task는 기본적으로 다음 중 하나의 상태로 존재한다.

- Running : 프로세스가 실행중이거나 CPU 사용을 위해 대기중임.
- Waiting : 프로세스가 event/resource를 사용하기 위해 waiting/sleeping 중임.

`Running 상태의 task`(TASK_RUNNING)는 run queue에 속해있는 task다. CPU를 즉시 사용할 수 있거나 가까운 미래에 실행될 수 있다.

`Waiting 상태의 task`는 어떠한 CPU에서도 실행되고 있지 않다. wait queue나 signal에 의해 wake-up 될 수 있다. waiting task의 가장 기본적인 상태는 TASK_INTERRUPTIBLE(i.e. "sleeping" 상태가 중단될 수 있는 상태)

task state는 다음과 같이 정의된다.
``` c++
// [include/linux/sched.h]

#define TASK_RUNNING        0
#define TASK_INTERRUPTIBLE  1
// ... 다른 상태 변수들
```
state field는 직접 조작하거나 현재 task의 state를 수정하는 `__set_current_state()`를 사용하여 조작할 수 있다.
``` c++
// [include/linux/sched.h]

#define __set_current_state(state_value)            \
    do { current->state = (state_value); } while (0)
```

## Queue 실행
`rq(run queue)` 구조체는 스케쥴러에서 가장 중요한 데이터 구조중 하나다. 모든 task는 run queue에 올라가 있으며, CPU에 의해 실행될 것이다. 모든 CPU는 각자의 run queue를 가지고 있다. 이는 지정된 CPU로 실행하기 위해 스케쥴러에 의해 선택 가능한 task의 리스트를 가지고 있다. 또한 스케쥴러가 각 task에 의해 공평한 선택을 하기 위해 사용하는 통계를 가지고 있으며, 이를 통해 CPU 부하를 줄일 수 있다(i.e. cpu migration).
``` c++
// [kernel/sched.c]

struct rq {
  unsigned long nr_running;   // <----- 통계 관련 데이터
  u64 nr_switches;            // <----- 통계 관련 데이터
  struct task_struct *curr;   // <----- 현재 CPU를 사용중인 task
  // ...
};
```
> 🔍 CFS(Complete Fair Scheduler)를 사용하면 실제 task list가 저장되는 방식이 다소 복잡하지만 여기서 문제되진 않는다.

당연하게도 run queue에서 빠져나온 task는 실행되지 않는다(i.e. 실행할 CPU가 없음). `deactivate_task()`가 바로 이러한 run queue에서 task를 빼내는 작업을 한다. 반대로 `activate_task()`는 run queue에 task를 넣는 작업을 한다.

## task와 schedule() 차단
task가 running 상태에서 waiting 상태로 전환되려면 다음 두 가지 이상을 동작을 수행해야한다.

1. 스스로의 running state를 `TASK_INTERRUPTIBLE` 상태로 변경
2. `deactivat_task()`를 호출하여 run queue 밖으로 빠져나옴.

실제로 아무도 diactivate_task()를 직접 호출하지 않는다. 대신, schedule()이 호출된다.

schedule() 함수는 스케쥴러의 메인이 되는 함수다. 이 함수가 호출될 때, 다음 running task는 CPU를 사용할 수 있도록 선택될 것이다. 고로, run queue의 `curr` 필드를 업데이트해야한다.


``` c++
asmlinkage void __sched schedule(void)
{
struct task_struct *prev, *next;
unsigned long *switch_count;
struct rq *rq;
int cpu;

    // ... cut ...

prev = rq->curr;    // <---- "prev" is the task running on the current CPU

if (prev->state && !(preempt_count() & PREEMPT_ACTIVE)) {   // <----- ignore the "preempt" stuff
    if (unlikely(signal_pending_state(prev->state, prev)))
    prev->state = TASK_RUNNING;
    else
    deactivate_task(rq, prev, DEQUEUE_SLEEP);     // <----- task is moved out of run queue
    switch_count = &prev->nvcsw;
}

// ... cut (choose the next task) ...
}
```


``` c++
void make_it_block(void)
{
  __set_current_state(TASK_INTERRUPTIBLE);
  schedule();
}
```


``` c++
// [include/linux/wait.h]

typedef struct __wait_queue_head wait_queue_head_t;

struct __wait_queue_head {
    spinlock_t lock;
    struct list_head task_list;
};
```


``` c++
// [include/linux.wait.h]

typedef struct __wait_queue wait_queue_t;
typedef int (*wait_queue_func_t)(wait_queue_t *wait, unsigned mode, int flags, void *key);

struct __wait_queue {
    unsigned int flags;
    void *private;                
    wait_queue_func_t func;     // <----- we will get back to this
    struct list_head task_list;
};
```

``` c++
// [include/linux/wait.h]

#define __WAITQUEUE_INITIALIZER(name, tsk) {                \
    .private    = tsk,                      \
    .func       = default_wake_function,            \
    .task_list  = { NULL, NULL } }

#define DECLARE_WAITQUEUE(name, tsk)                    \
    wait_queue_t name = __WAITQUEUE_INITIALIZER(name, tsk) // <----- it creates a variable!
```

``` c++
DECLARE_WAITQUEUE(my_wait_queue_elt, current); // <----- use the "current" macro
```



``` c++
// [kernel/wait.c]

void add_wait_queue(wait_queue_head_t *q, wait_queue_t *wait)
{
    unsigned long flags;

    wait->flags &= ~WQ_FLAG_EXCLUSIVE;
    spin_lock_irqsave(&q->lock, flags);
    __add_wait_queue(q, wait);              // <----- here
    spin_unlock_irqrestore(&q->lock, flags);
}

static inline void __add_wait_queue(wait_queue_head_t *head, wait_queue_t *new)
{
    list_add(&new->task_list, &head->task_list);
}
```


``` c++
// [kernel/sched.c]

/**
 * __wake_up - wake up threads blocked on a waitqueue.
 * @q: the waitqueue
 * @mode: which threads
 * @nr_exclusive: how many wake-one or wake-many threads to wake up
 * @key: is directly passed to the wakeup function
 *
 * It may be assumed that this function implies a write memory barrier before
 * changing the task state if and only if any tasks are woken up.
 */

void __wake_up(wait_queue_head_t *q, unsigned int mode,
            int nr_exclusive, void *key)
{
    unsigned long flags;

    spin_lock_irqsave(&q->lock, flags);
    __wake_up_common(q, mode, nr_exclusive, 0, key);    // <----- here
    spin_unlock_irqrestore(&q->lock, flags);
}
```

``` c++
// [kernel/sched.c]

static void __wake_up_common(wait_queue_head_t *q, unsigned int mode,
        int nr_exclusive, int wake_flags, void *key)
{
    wait_queue_t *curr, *next;

[0]   list_for_each_entry_safe(curr, next, &q->task_list, task_list) {
    unsigned flags = curr->flags;

[1]     if (curr->func(curr, mode, wake_flags, key) &&
        (flags & WQ_FLAG_EXCLUSIVE) && !--nr_exclusive)
        break;
    }
}
```